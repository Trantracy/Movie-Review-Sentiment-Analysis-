{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "FTMLE_Logistic Regression Exercise.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trantracy/Movie-Review-Sentiment-Analysis-/blob/master/Movie-Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MDEjcL7Lgs2",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHQ1QCGHLgs4",
        "colab_type": "text"
      },
      "source": [
        "## Basic NLP Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaTMGLDPLgs4",
        "colab_type": "text"
      },
      "source": [
        "- **Step 1**: Clean data\n",
        "    - Remove all irrelevant characters such as any non alphanumeric characters\n",
        "    - Tokenize your text by separating it into individual words \n",
        "    - Remove words that are not relevant, such as “@” twitter mentions or urls \n",
        "    - Convert all characters to **lowercase**, in order to treat words such as “hello”, “Hello”, and “HELLO” the same \n",
        "    - Consider **lemmatization** (reduce words such as “am”, “are”, and “is” to a common form such as “be”)\n",
        "- **Step 2**: Representation\n",
        "    - Bag of Words or TFIDF\n",
        "- **Step 3**: Classification\n",
        "    - Naive Bayes\n",
        "    - Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQuoh8HSOs9F",
        "colab_type": "code",
        "outputId": "2dfcc546-5fbb-4bd4-9234-70227bca0336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPtgQIuhLgtd",
        "colab_type": "code",
        "outputId": "f4ed84c3-fc01-4aa8-f059-70cf42d8701a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# Import pandas, numpy and the dataset, save it in a object called 'sentiment'\n",
        "# Your code here\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Read file with param './data/train.csv', encoding='latin-1'\n",
        "sentiment = pd.read_csv('/content/drive/My Drive/Student Files/FTMLE - Tonga/Data/sentiment.csv', encoding='latin-1')\n",
        "\n",
        "# Let's check sentiment.head(10) and sample(10)\n",
        "# Your code here\n",
        "sentiment.sample(10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ItemID</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>SentimentText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84404</th>\n",
              "      <td>84416</td>\n",
              "      <td>1</td>\n",
              "      <td>@catieronquillo, the world is wide.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99603</th>\n",
              "      <td>99615</td>\n",
              "      <td>0</td>\n",
              "      <td>@Crossbow1 YOU'RE TELLING ME.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9666</th>\n",
              "      <td>9678</td>\n",
              "      <td>0</td>\n",
              "      <td>&amp;quot;Lars and the Real Girl&amp;quot; is such a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8154</th>\n",
              "      <td>8157</td>\n",
              "      <td>1</td>\n",
              "      <td>#unfollowdiddy and follow me instead! i am coo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99044</th>\n",
              "      <td>99056</td>\n",
              "      <td>1</td>\n",
              "      <td>@craftygirljen I shall consider it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65203</th>\n",
              "      <td>65215</td>\n",
              "      <td>1</td>\n",
              "      <td>@breakinporcelan I'm looking for it right now....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5417</th>\n",
              "      <td>5420</td>\n",
              "      <td>1</td>\n",
              "      <td>#followfriday go follow @brendonuriesays and @...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88715</th>\n",
              "      <td>88727</td>\n",
              "      <td>1</td>\n",
              "      <td>@circus_clown In passing you may have</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25422</th>\n",
              "      <td>25434</td>\n",
              "      <td>0</td>\n",
              "      <td>@3b1srobinson my dogs get me up at 6am</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41300</th>\n",
              "      <td>41312</td>\n",
              "      <td>0</td>\n",
              "      <td>@andrzejkala Me too. Shall we arrange somethin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ItemID  Sentiment                                      SentimentText\n",
              "84404   84416          1               @catieronquillo, the world is wide. \n",
              "99603   99615          0                     @Crossbow1 YOU'RE TELLING ME. \n",
              "9666     9678          0  &quot;Lars and the Real Girl&quot; is such a s...\n",
              "8154     8157          1  #unfollowdiddy and follow me instead! i am coo...\n",
              "99044   99056          1               @craftygirljen I shall consider it. \n",
              "65203   65215          1  @breakinporcelan I'm looking for it right now....\n",
              "5417     5420          1  #followfriday go follow @brendonuriesays and @...\n",
              "88715   88727          1             @circus_clown In passing you may have \n",
              "25422   25434          0            @3b1srobinson my dogs get me up at 6am \n",
              "41300   41312          0  @andrzejkala Me too. Shall we arrange somethin..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw-RQlFgLgtc",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment analysis\n",
        "This contest is taken from the real task of Text Processing.\n",
        "\n",
        "The task is to build a model that will determine the tone (positive, negative) of the text. To do this, you will need to train the model on the existing data (train.csv). The resulting model will have to determine the class (neutral, positive, negative) of new texts. The dataset contains the following fields:\n",
        "\n",
        "| Field name | Meaning |\n",
        "|------------|-----------|\n",
        "| ItemID  | id of tweet|\n",
        "| Sentiment | sentiment (1-positive, 0-negative)|\n",
        "| SentimentText | text of the tweet|\n",
        "\n",
        "Let's first of all have a look at the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pf4J4gbLgtf",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the structure of a tweet varies a lot between tweet and tweet. They have different lengths, letters, numbers, extrange characters, etc. \n",
        "\n",
        "It is also important to note that **a lot** of words are not correctly spelled, for example the word _\"Juuuuuuuuuuuuuuuuussssst\"_ or the word _\"sooo\"_\n",
        "\n",
        "This makes it hard to mesure how positive or negative are the words within the tweets.\n",
        "\n",
        "So we need a way of scoring the words such that words that appear in positive tweets have greater score that those that appear in negative tweets.\n",
        "\n",
        "But first... how do we represent the tweets as vectors we can input to our algorithm?\n",
        "\n",
        "### Bag of words\n",
        "\n",
        "One thing we could do to represent the tweets as equal-sized vectors of numbers is the following:\n",
        "\n",
        "* Create a list (vocabulary) with all the unique words in the whole corpus of tweets. \n",
        "* We construct a feature vector from each tweet that contains the counts of how often each word occurs in the particular tweet\n",
        "\n",
        "_Note that since the unique words in each tweet represent only a small subset of all the words in the bag-of-words vocabulary, the feature vectors will mostly consist of zeros_\n",
        "\n",
        "Lets construct the bag of words. We will work with a smaller example for illustrative purposes, and at the end we will work with our real data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj7doPrzLgtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = [\n",
        "    'This is amazing!',\n",
        "    'ML is the best, yes it is',\n",
        "    'I am not sure about how this is going to end...'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmrZTyBZLgti",
        "colab_type": "text"
      },
      "source": [
        "Let's import [CountVectorizer.](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) It'll help us to convert a collection of text documents to a matrix of token counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJrKCJrYOAGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define an object of CountVectorizer() as count\n",
        "# This will convert our documents into matrices of count\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count = CountVectorizer()\n",
        "\n",
        "# With count object, fit and transfom your tweets and save result in a variable name 'bag'\n",
        "# Your code here\n",
        "bag = count.fit_transform(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3JxC1tELgtl",
        "colab_type": "code",
        "outputId": "982e1971-ca50-4de0-b334-19e8e9bc9447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# Find in document of CountVectorizer a function that show us list of feature names\n",
        "# hint: get_feature_names\n",
        "# Your code here\n",
        "count.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['about',\n",
              " 'am',\n",
              " 'amazing',\n",
              " 'best',\n",
              " 'end',\n",
              " 'going',\n",
              " 'how',\n",
              " 'is',\n",
              " 'it',\n",
              " 'ml',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'the',\n",
              " 'this',\n",
              " 'to',\n",
              " 'yes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc6hKP5VLgtn",
        "colab_type": "text"
      },
      "source": [
        "As we can see from executing the preceding command, the vocabulary is stored in a Python array that maps the unique words to integer indices. Next, let's print the feature vectors that we just created:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8NB9NvfLgto",
        "colab_type": "code",
        "outputId": "a20b3e44-53dd-4a33-c265-52caa3a70cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Call toarray() on your 'bag' to see the feature vectors\n",
        "# Your code here\n",
        "bag.toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 1],\n",
              "       [1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ_JDGfiLgtr",
        "colab_type": "code",
        "outputId": "df45a4ca-8e95-4e18-fee2-fe153a288458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# What is the index of the word 'is' and how many times it occurs in all three tweets?\n",
        "# Hint: You can directly count on feature fectors\n",
        "# Your answer here\n",
        "count.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'about': 0,\n",
              " 'am': 1,\n",
              " 'amazing': 2,\n",
              " 'best': 3,\n",
              " 'end': 4,\n",
              " 'going': 5,\n",
              " 'how': 6,\n",
              " 'is': 7,\n",
              " 'it': 8,\n",
              " 'ml': 9,\n",
              " 'not': 10,\n",
              " 'sure': 11,\n",
              " 'the': 12,\n",
              " 'this': 13,\n",
              " 'to': 14,\n",
              " 'yes': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZF6rcW_Lgtt",
        "colab_type": "text"
      },
      "source": [
        "Each index position in the feature vectors corresponds to the integer values that are stored as dictionary items in the CountVectorizer vocabulary. For example, the first feature at index position 0 resembles the count of the word 'about' , which only occurs in the last document. These values in the feature vectors are also called the **raw term frequencies**: `tf(t,d )` —the number of times a term `t` occurs in a document `d`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_dqddptLgtu",
        "colab_type": "text"
      },
      "source": [
        "### How relevant are words? Term frequency-inverse document frequency\n",
        "\n",
        "We could use these raw term frequencies to score the words in our algorithm. There is a problem though: If a word is very frequent in _all_ documents, then it probably doesn't carry a lot of information. In order to tacke this problem we can use **term frequency-inverse document frequency**, which will reduce the score the more frequent the word is accross all tweets. It is calculated like this:\n",
        "\n",
        "\\begin{equation*}\n",
        "tf-idf(t,d) = tf(t,d) ~ idf(t,d)\n",
        "\\end{equation*}\n",
        "\n",
        "_tf(t,d)_ is the raw term frequency descrived above. _idf(t,d)_ is the inverse document frequency, than can be calculated as follows:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\log \\frac{n_d}{1+df\\left(d,t\\right)}\n",
        "\\end{equation*}\n",
        "\n",
        "where `n` is the total number of documents and _df(t,d)_ is the number of documents where the term `t` appears. \n",
        "\n",
        "The `1` addition in the denominator is just to avoid zero term for terms that appear in all documents, will not be entirely ignored. Ans the `log` ensures that low frequency term don't get too much weight.\n",
        "\n",
        "Fortunately for us `scikit-learn` does all those calculations for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as19_GljLgtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# Formatting the number to 2 digits after the decimal point by showing on this notebook\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "# Feed the tf-idf Vectorizer with tweets using fit_transform()\n",
        "tfidf_vec = tfidf.fit_transform(tweets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ1AsSSWQtqg",
        "colab_type": "code",
        "outputId": "90f9e50f-0925-4851-df43-f45c84c5bfe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "tfidf.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['about',\n",
              " 'am',\n",
              " 'amazing',\n",
              " 'best',\n",
              " 'end',\n",
              " 'going',\n",
              " 'how',\n",
              " 'is',\n",
              " 'it',\n",
              " 'ml',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'the',\n",
              " 'this',\n",
              " 'to',\n",
              " 'yes']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H234IVZtLgtw",
        "colab_type": "code",
        "outputId": "e951ccc7-265d-4a82-bd60-bc0eff944d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Now what is the weight of the word 'is' and 'amazing'?\n",
        "# hint: using \n",
        "# tfidf.get_feature_names()\n",
        "# tfidf_vec.toarray()\n",
        "# Your answer here\n",
        "tfidf_vec.toarray()[:,7].mean()\n",
        "tfidf_vec.toarray()[:,2].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24011114968499644"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ErR308Lgtz",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Data clean up\n",
        "\n",
        "### Removing stop words\n",
        "\n",
        "Now that we know how to format and score our input. Let's look at our **real** vocabulary. Specifically, the most common words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ON_CLCLgLgtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Example\n",
        "count = Counter()\n",
        "for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:\n",
        "    count[word] += 1\n",
        "print(count)\n",
        "print(count.most_common(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kAfdY7CLgt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "\n",
        "# Let's apply the example above to count words in our SentimentText\n",
        "# Your code here\n",
        "for document in sentiment['SentimentText']:\n",
        "  for word in document.split(' '):\n",
        "    vocab[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBHBd1yLSd36",
        "colab_type": "code",
        "outputId": "264be2ba-aae3-46b3-db92-fc4fd7646ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "vocab.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 123916),\n",
              " ('I', 32879),\n",
              " ('to', 28810),\n",
              " ('the', 28087),\n",
              " ('a', 21321),\n",
              " ('you', 21180),\n",
              " ('i', 15995),\n",
              " ('and', 14565),\n",
              " ('it', 12818),\n",
              " ('my', 12385),\n",
              " ('for', 12149),\n",
              " ('in', 11199),\n",
              " ('is', 11185),\n",
              " ('of', 10326),\n",
              " ('that', 9181),\n",
              " ('on', 9020),\n",
              " ('have', 8991),\n",
              " ('me', 8255),\n",
              " ('so', 7612),\n",
              " ('but', 7220)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A94oAnZLgt3",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the most common words are meaningless in terms of sentiment: _I, to, the, and_... they don't give any information on positiveness or negativeness. They're basically **noise** that can most probably be eliminated. These kind of words are called _stop words_, and it is a common practice to remove them when doing text analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeWTMVcyLgt4",
        "colab_type": "code",
        "outputId": "beb9dc74-6dd6-42af-9b8b-cd6bf9f08b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSjQwJ5iLgt8",
        "colab_type": "code",
        "outputId": "159204df-5712-444c-9499-e0078d3698d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "vocab_reduced = Counter()\n",
        "# Go through all of the items of vocab using vocab.items() and pick only words that are not in 'stop' \n",
        "# and save them in vocab_reduced\n",
        "# Your code here\n",
        "for word, count in vocab.items():\n",
        "  if not word in stop:\n",
        "    vocab_reduced[word] = count\n",
        "\n",
        "vocab_reduced.most_common(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('', 123916),\n",
              " ('I', 32879),\n",
              " (\"I'm\", 6416),\n",
              " ('like', 5086),\n",
              " ('-', 4922),\n",
              " ('get', 4864),\n",
              " ('u', 4194),\n",
              " ('good', 3953),\n",
              " ('love', 3494),\n",
              " ('know', 3472),\n",
              " ('go', 2990),\n",
              " ('see', 2868),\n",
              " ('one', 2787),\n",
              " ('got', 2774),\n",
              " ('think', 2613),\n",
              " ('&amp;', 2556),\n",
              " ('lol', 2419),\n",
              " ('going', 2396),\n",
              " ('really', 2287),\n",
              " ('im', 2200)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xji-S78TLgt-",
        "colab_type": "text"
      },
      "source": [
        "This looks better, only in the 20 most common words we already see words that make sense: good, love, really... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z01BpBz7Lgt-",
        "colab_type": "text"
      },
      "source": [
        "### Removing special characters and \"trash\"\n",
        "\n",
        "If you look closer, you'll see that we're also taking into consideration punctuation signs ('-', ',', etc) and other html tags like `&amp`. We can definitely remove them for the sentiment analysis, but we will try to keep the emoticons, since those _do_ have a sentiment load:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9pqiFUXLgt_",
        "colab_type": "code",
        "outputId": "5aff8db7-30d7-411e-8417-2e21fa94017e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocessor(text):\n",
        "    \"\"\" Return a cleaned version of text\n",
        "    \"\"\"\n",
        "    # Remove HTML markup\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    # Save emoticons for later appending\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Create some random texts for testing the function preprocessor()\n",
        "print(preprocessor(''))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6mimtiSLguB",
        "colab_type": "text"
      },
      "source": [
        "We are almost ready! There is another trick we can use to reduce our vocabulary and consolidate words. If you think about it, words like: love, loving, etc. _Could_ express the same positivity. If that was the case, we would be  having two words in our vocabulary when we could have only one: lov. This process of reducing a word to its root is called **stemming**.\n",
        "\n",
        "We also need a _tokenizer_ to break down our tweets in individual words. We will implement two tokenizers, a regular one and one that does steaming:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zrr34DRLguB",
        "colab_type": "code",
        "outputId": "97f09041-9bad-4993-fe00-d4c1f123fe8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "# write a function called `tokenizer()` that split a text into list of words\n",
        "def tokenizer(text):\n",
        "    # Your code here\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "# write a function named `tokenizer_porter()` that split a text into list of words and apply stemming technic\n",
        "# Hint: porter.stem(word)\n",
        "def tokenizer_porter(text):\n",
        "    # Your code here\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "# Testing\n",
        "print(tokenizer('Hi there, I am loving this, like with a lot of love'))\n",
        "print(tokenizer_porter('Hi there, I am loving this, like with a lot of love'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hi', 'there,', 'I', 'am', 'loving', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n",
            "['Hi', 'there,', 'I', 'am', 'love', 'this,', 'like', 'with', 'a', 'lot', 'of', 'love']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpOHUj0QLguG",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsZUZT0ILguH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    # Your code here\n",
        "    return [porter.stem(word) for word in text.split()]\n",
        "\n",
        "def preprocessor(text):\n",
        "    \"\"\" Return a cleaned version of text\n",
        "    \"\"\"\n",
        "    # Remove HTML markup\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    # Save emoticons for later appending\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "    # Remove any non-word character and append the emoticons,\n",
        "    # removing the nose character for standarization. Convert to lower case\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
        "    \n",
        "    return text\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words=stop,\n",
        "                        tokenizer=tokenizer_porter,\n",
        "                        preprocessor=preprocessor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96CGvWnKLguJ",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Classification\n",
        "\n",
        "We are finally ready to train our algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quMv4bXNLguD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset in train and test\n",
        "# Your code here\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = sentiment['SentimentText']\n",
        "\n",
        "y = sentiment['Sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMA_qTW5LguJ",
        "colab_type": "code",
        "outputId": "4397583c-bb53-4c94-cbd4-3003022fcda6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# A pipeline is what chains several steps together, once the initial exploration is done. \n",
        "# For example, some codes are meant to transform features — normalise numericals, or turn text into vectors, \n",
        "# or fill up missing data, they are transformers; other codes are meant to predict variables by fitting an algorithm,\n",
        "# they are estimators. Pipeline chains all these together which can then be applied to training data\n",
        "clf = Pipeline([('vect', tfidf),\n",
        "                ('clf', LogisticRegression(random_state=0))])\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=<function preprocessor at 0x7f19fb484488>,\n",
              "                                 smooth_idf=True,\n",
              "                                 stop_words=['i', 'me', 'my', 'myself', '...\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function tokenizer_porter at 0x7f19fb44eb70>,\n",
              "                                 use_idf=True, vocabulary=None)),\n",
              "                ('clf',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=0,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yonP8E3vLguL",
        "colab_type": "code",
        "outputId": "87792a62-e1d1-4fd2-8bc4-e0f3056fc719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Now apply those above metrics to evaluate your model\n",
        "# Your code here\n",
        "predictions = clf.predict(X_test)\n",
        "accuracy_score(y_test, predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7546254625462546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmaY3lyrX_p5",
        "colab_type": "code",
        "outputId": "da792f84-f299-431a-e364-d50b48df6e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.67      0.71      8804\n",
            "           1       0.76      0.82      0.79     11194\n",
            "\n",
            "    accuracy                           0.75     19998\n",
            "   macro avg       0.75      0.75      0.75     19998\n",
            "weighted avg       0.75      0.75      0.75     19998\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wygc7NDsLguN",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's run some tests :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcgsonCxLguO",
        "colab_type": "code",
        "outputId": "19afb67a-9266-4585-9f4f-c5ac1fda2db8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "tweets = [\n",
        "    \"This is really bad\",\n",
        "    \"I love this!\",\n",
        "    \":)\",\n",
        "]\n",
        "\n",
        "preds = clf.predict_proba(tweets)\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "    print(f'{tweets[i]} --> Negative, Positive = {preds[i]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is really bad --> Negative, Positive = [0.96 0.04]\n",
            "I love this! --> Negative, Positive = [0.07 0.93]\n",
            ":) --> Negative, Positive = [0.39 0.61]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMlRKsLxLguQ",
        "colab_type": "text"
      },
      "source": [
        "If we would like to use the classifier in another place, or just not train it again and again everytime, we can save the model in a pickle file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfdBKUEELguQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "pickle.dump(clf, open(os.path.join('logisticRegression.pkl'), 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHSHPhbwZisR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pickle.load(open('logisticRegression.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0uiVxC9OCSL",
        "colab_type": "text"
      },
      "source": [
        "**Good Job!**"
      ]
    }
  ]
}